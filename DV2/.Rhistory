dataset <- read.csv("/home/amir/Documents/goesto_Github/data_visulization_R/chip_dataset.csv", header = TRUE, sep=',')
# Calculate percentage of missing values in each column
missing_percentages <- colMeans(is.na(dataset)) * 100
# Print the percentage of missing values in each column
print(missing_percentages)
follow > https://www.kaggle.com/code/gap505/cpu-data-analysis
dataset <- read.csv("/home/amir/Documents/goesto_Github/data_visulization_R/chip_dataset.csv", header = TRUE, sep=',')
# Calculate percentage of missing values in each column
missing_percentages <- colMeans(is.na(dataset)) * 100
# Print the percentage of missing values in each column
print(missing_percentages)
## follow > https://www.kaggle.com/code/gap505/cpu-data-analysis
dataset <- read.csv("/home/amir/Documents/goesto_Github/data_visulization_R/chip_dataset.csv", header = TRUE, sep=',')
# Calculate percentage of missing values in each column
missing_percentages <- colMeans(is.na(dataset)) * 100
# Print the percentage of missing values in each column
print(missing_percentages)
## follow > https://www.kaggle.com/code/gap505/cpu-data-analysis
# Check the type of the dataset
cat("Type of dataset:", class(dataset), "\n")
# Remove the specified columns
dataset <- subset(dataset, select = -c(FP16.GFLOPS, FP32.GFLOPS, FP64.GFLOPS))
# Print the modified dataset
print(dataset)
# Print the modified dataset
dataset <- read.csv("/home/amir/Documents/goesto_Github/data_visulization_R/chip_dataset.csv", header = TRUE, sep=',')
# Calculate percentage of missing values in each column
missing_percentages <- colMeans(is.na(dataset)) * 100
# Print the percentage of missing values in each column
print(missing_percentages)
## follow > https://www.kaggle.com/code/gap505/cpu-data-analysis
# Check the type of the dataset
cat("Type of dataset:", class(dataset), "\n")
# Remove the specified columns
dataset <- subset(dataset, select = -c(FP16.GFLOPS, FP32.GFLOPS, FP64.GFLOPS))
# Print the modified dataset
print(summary(dataset))
# Print column names line by line
for (col in names(dataset)) {
cat(col, "\n")
# Print column names line by line
for (col in names(dataset)) {
print(col, "\n")
}
# Print column names line by line
for (col in names(dataset)) {
cat(col, "\n")
}
# Print column names line by line
for (col in names(dataset)) {
print(col)
}
print(colnames(dataset))
colnames(dataset)
dataset <- read.csv("/home/amir/Documents/goesto_Github/data_visulization_R/chip_dataset.csv", header = TRUE, sep=',')
# Calculate percentage of missing values in each column
missing_percentages <- colMeans(is.na(dataset)) * 100
# Print the percentage of missing values in each column
print(missing_percentages)
## follow > https://www.kaggle.com/code/gap505/cpu-data-analysis
# Check the type of the dataset
cat("Type of dataset:", class(dataset), "\n")
# Remove the specified columns
dataset <- subset(dataset, select = -c(FP16.GFLOPS, FP32.GFLOPS, FP64.GFLOPS))
print(summary(dataset))
# Print column names
sort(colnames(dataset))
dataset <- read.csv("/home/amir/Documents/goesto_Github/data_visulization_R/chip_dataset.csv", header = TRUE, sep=',')
# Calculate percentage of missing values in each column
missing_percentages <- colMeans(is.na(dataset)) * 100
# Print the percentage of missing values in each column
print(missing_percentages)
## follow > https://www.kaggle.com/code/gap505/cpu-data-analysis
# Check the type of the dataset
cat("Type of dataset:", class(dataset), "\n")
# Remove the specified columns
dataset <- subset(dataset, select = -c(FP16.GFLOPS, FP32.GFLOPS, FP64.GFLOPS))
print(summary(dataset))
# Print column names
sort(colnames(dataset))
dataset <- read.csv("/home/amir/Documents/goesto_Github/data_visulization_R/chip_dataset.csv", header = TRUE, sep=',')
# Calculate percentage of missing values in each column
missing_percentages <- colMeans(is.na(dataset)) * 100
# Print the percentage of missing values in each column
print(missing_percentages)
## follow > https://www.kaggle.com/code/gap505/cpu-data-analysis
# Check the type of the dataset
cat("Type of dataset:", class(dataset), "\n")
# Remove the specified columns
dataset <- subset(dataset, select = -c(FP16.GFLOPS, FP32.GFLOPS, FP64.GFLOPS))
print(summary(dataset))
# Print column names
sort(colnames(dataset))
dataset <- read.csv("/home/amir/Documents/goesto_Github/data_visulization_R/chip_dataset.csv", header = TRUE, sep=',')
# Calculate percentage of missing values in each column
missing_percentages <- colMeans(is.na(dataset)) * 100
# Print the percentage of missing values in each column
print(missing_percentages)
dataset <- read.csv("/home/amir/Documents/goesto_Github/data_visulization_R/chip_dataset.csv", header = TRUE, sep=',')
# Calculate percentage of missing values in each column
missing_percentages <- colMeans(is.na(dataset)) * 100
# Print the percentage of missing values in each column
print(missing_percentages)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
dataset <- read.csv("/home/amir/Documents/goesto_Github/data_visulization_R/chip_dataset.csv", header = TRUE, sep=',')
# Calculate percentage of missing values in each column
missing_percentages <- colMeans(is.na(dataset)) * 100
# Print the percentage of missing values in each column
print(missing_percentages)
# Check the type of the dataset
cat("Type of dataset:", class(dataset), "\n")
# Remove the specified columns
dataset <- subset(dataset, select = -c(FP16.GFLOPS, FP32.GFLOPS, FP64.GFLOPS))
print(summary(dataset))
# Print column names
sort(colnames(dataset))
# Print column names line by line
for (col_name in colnames(dataset)) {
print(col_name)
}
# Print the type of each column
sapply(dataset, class)
# Load necessary libraries
library(modeest)
# Check for NaN values in each column
for (col in colnames(dataset)) {
if (class(dataset[[col]]) == "integer" | class(dataset[[col]]) == "character") {
# Replace NaN with mode for integer and character columns
mode_val <- mlv(dataset[[col]], method = "mfv")
dataset[[col]][is.na(dataset[[col]])] <- mode_val
} else if (class(dataset[[col]]) == "numeric") {
# Replace NaN with mean for numeric columns
mean_val <- mean(dataset[[col]], na.rm = TRUE)
dataset[[col]][is.na(dataset[[col]])] <- mean_val
}
}
# Check for NaN values in each column and replace them
for (col in colnames(dataset)) {
if (class(dataset[[col]]) == "integer" | class(dataset[[col]]) == "character") {
# Replace NaN with mode for integer and character columns
mode_val <- names(sort(-table(dataset[[col]])))[1]
dataset[[col]][is.na(dataset[[col]])] <- mode_val
} else if (class(dataset[[col]]) == "numeric") {
# Replace NaN with mean for numeric columns
mean_val <- mean(dataset[[col]], na.rm = TRUE)
dataset[[col]][is.na(dataset[[col]])] <- mean_val
}
}
# Print the updated dataset
print(dataset)
# Check for NaN values in each column
nan_count <- colSums(is.na(dataset))
# Check for empty values in each column (for character columns)
empty_count <- colSums(dataset == "")
# Print the counts
print("NaN counts:")
print(nan_count)
print("Empty counts:")
print(empty_count)
# Select only numerical columns
numerical_columns <- dataset[, sapply(dataset, is.numeric)]
# Create a separate plot for each numerical column
for (col in colnames(numerical_columns)) {
hist(numerical_columns[[col]], main = col, xlab = "Value", col = "skyblue", border = "black")
}
# Select only numeric and integer columns
numeric_integer_columns <- dataset[, sapply(dataset, function(x) is.numeric(x) || is.integer(x))]
# Create a separate plot for each numeric and integer column
par(mfrow = c(ceiling(sqrt(ncol(numeric_integer_columns))), ceiling(sqrt(ncol(numeric_integer_columns)))))
for (col in colnames(numeric_integer_columns)) {
hist(numeric_integer_columns[[col]], main = col, xlab = "Value", col = "skyblue", border = "black")
}
# Select only numeric and integer columns
numeric_integer_columns <- dataset[, sapply(dataset, function(x) is.numeric(x) || is.integer(x))]
# Create a separate plot for each numeric and integer column
par(mfrow = c(ceiling(sqrt(ncol(numeric_integer_columns))), ceiling(sqrt(ncol(numeric_integer_columns)))))
for (col in colnames(numeric_integer_columns)) {
hist(numeric_integer_columns[[col]], main = col, xlab = "Value", col = "skyblue", border = "black")
}
# Select only numeric and integer columns
# Find the numeric and integer columns
numeric_integer_columns <- dataset[, sapply(dataset, function(x) is.numeric(x) || is.integer(x))]
# Create a separate plot for each numeric and integer column
par(mfrow = c(ceiling(sqrt(ncol(numeric_integer_columns))), ceiling(sqrt(ncol(numeric_integer_columns)))))
for (col in colnames(numeric_integer_columns)) {
hist(numeric_integer_columns[[col]], main = col, xlab = "Value", col = "skyblue", border = "black")
}
# Find the numeric and integer columns
numeric_integer_columns <- dataset[, sapply(dataset, function(x) is.numeric(x) || is.integer(x))]
# Calculate the number of rows and columns for the plot grid
num_cols <- ceiling(sqrt(ncol(numeric_integer_columns)))
num_rows <- ceiling(ncol(numeric_integer_columns) / num_cols)
# Set the plot layout
par(mfrow = c(num_rows, num_cols))
# Create a separate plot for each numeric and integer column
for (col in colnames(numeric_integer_columns)) {
hist(numeric_integer_columns[[col]], main = col, xlab = "Value", col = "skyblue", border = "black")
}
# Find the character columns
character_columns <- dataset[, sapply(dataset, is.character)]
# Create a separate pie chart for each character column
for (col in colnames(character_columns)) {
# Count the frequency of each unique value in the column
value_counts <- table(character_columns[[col]])
# Plot a pie chart
pie(value_counts, main = col)
}
